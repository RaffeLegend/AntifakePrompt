{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pretrained_ans = np.array([0, 1, 0, 1, 1], dtype=np.int64)\n",
    "finetuned_ans = np.array([0, 0, 1, 1, 0], dtype=np.int64)\n",
    "\n",
    "final_ans = np.ceil((pretrained_ans + finetuned_ans)/2).astype(np.int64)\n",
    "final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-07-31 21:11:28.002746: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.038551839337380045"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import lavis\n",
    "from lavis.models import load_model_and_preprocess\n",
    " \n",
    "import random \n",
    "random.seed(43)\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextInvDataset(Dataset):\n",
    "    def __init__(self, csv, vis_processors=None, txt_processors=None):\n",
    "        \n",
    "        self.path_and_labels = pd.read_csv(csv, index_col=\"img_path\")\n",
    "        self.vis_processors = vis_processors\n",
    "        self.txt_processors = txt_processors\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(list(self.path_and_labels.index))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        image_path = list(self.path_and_labels.index)[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.vis_processors:\n",
    "            image = self.vis_processors(image)\n",
    "        \n",
    "        label = self.path_and_labels.loc[image_path, \"label\"]\n",
    "        \n",
    "        is_uncommon = \"uncommon\" in image_path\n",
    "\n",
    "        return image, label, is_uncommon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is for query lost of images\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "class InstructBLIP():\n",
    "    def __init__(self, name=\"blip2_vicuna_instruct_textinv\", model_type=\"vicuna7b\", is_eval=True, device=\"cpu\") -> None:\n",
    "        print(f'Loading model...')\n",
    "        #self.model, self.vis_processors, self.txt_processors = load_model_and_preprocess(name, model_type, is_eval, device)\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # QA\n",
    "        self.question = \"\"\n",
    "        \n",
    "        # results\n",
    "        self.acc = None\n",
    "        self.confusion_mat = None\n",
    "        \n",
    "        self.acc_3class = None\n",
    "        self.confusion_mat_3class = None\n",
    "        \n",
    "        self.com_acc = None\n",
    "        self.com_confusion_mat = None\n",
    "        self.uncom_acc = None\n",
    "        self.uncom_confusion_mat = None\n",
    "\n",
    "    def LoadModels(self, model, vis_processors, txt_processors, device):\n",
    "        self.model = model\n",
    "        self.vis_processors = vis_processors\n",
    "        self.txt_processors = txt_processors\n",
    "        self.device = device\n",
    "    \n",
    "    def LoadImages(self, dir, num):\n",
    "        onlyfiles = []\n",
    "        \n",
    "        for f in sorted(listdir(dir)):\n",
    "            if isfile(join(dir, f)):\n",
    "                onlyfiles.append(join(dir, f))\n",
    "        \n",
    "        onlyfiles = random.sample(onlyfiles, num)\n",
    "        \n",
    "        raw_img_list = []\n",
    "        with tqdm(total=len(onlyfiles), desc=f'Loading imgs from {dir}') as pbar:\n",
    "            for f in onlyfiles:\n",
    "                raw_img = Image.open(f).convert(\"RGB\")\n",
    "                raw_img_list.append(raw_img)\n",
    "                pbar.update(1)\n",
    "        \n",
    "        return raw_img_list\n",
    "\n",
    "    def LoadData(self, real_dir, fake_dir, num=1000):\n",
    "        #real_imgs = LoadImages(join(root_dir, \"0_real\"))\n",
    "        #fake_imgs = LoadImages(join(root_dir, \"1_fake\"))\n",
    "        real_imgs = self.LoadImages(real_dir, num)\n",
    "        fake_imgs = self.LoadImages(fake_dir, num)\n",
    "        \n",
    "        self.imgs = real_imgs + fake_imgs\n",
    "        self.labels = [0]*len(real_imgs) + [1]*len(fake_imgs)\n",
    "        #return self.imgs, self.labels\n",
    "      \n",
    "    def LoadData_batch(self, csv_path):\n",
    "        self.dataset = TextInvDataset(csv=csv_path, vis_processors=self.vis_processors[\"eval\"])\n",
    "        self.dataloader = DataLoader(dataset=self.dataset, batch_size=8, shuffle=False, num_workers=8)    \n",
    "        \n",
    "    def LoadData3Class(self, real_dir, fake_common_dir, fake_uncommon_dir, num=[1000, 500, 500]):\n",
    "        #real_imgs = LoadImages(join(root_dir, \"0_real\"))\n",
    "        #fake_imgs = LoadImages(join(root_dir, \"1_fake\"))\n",
    "        self.num = num\n",
    "        real_imgs = self.LoadImages(real_dir, num[0])\n",
    "        fake_common_imgs = self.LoadImages(fake_common_dir, num[1])\n",
    "        fake_uncommon_imgs = self.LoadImages(fake_uncommon_dir, num[2])\n",
    "        \n",
    "        self.imgs = real_imgs + fake_common_imgs + fake_uncommon_imgs\n",
    "        self.labels = [0]*len(real_imgs) + [1]*(len(fake_common_imgs)+len(fake_uncommon_imgs))\n",
    "        self.label_3class = [0]*len(real_imgs) + [1]*len(fake_common_imgs) + [2]*len(fake_uncommon_imgs)\n",
    "        #return self.imgs, self.labels, self.label_3class\n",
    "\n",
    "    def QueryImgs(self, question, true_string=\"yes\"):\n",
    "        self.ans_list = []\n",
    "        self.question = question\n",
    "        \n",
    "        with tqdm(total=len(self.imgs), desc=f'Answering') as pbar:\n",
    "            for idx, img in enumerate(self.imgs):\n",
    "                image = self.vis_processors[\"eval\"](img).unsqueeze(0).to(self.device)\n",
    "\n",
    "                samples = {\"image\": image, \"text_input\": question}\n",
    "                \n",
    "                ans = self.model.predict_answers(samples=samples, inference_method=\"generate\")[0]\n",
    "                self.ans_list.append(0 if ans == true_string else 1)\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "        self.acc = accuracy_score(self.labels, self.ans_list)\n",
    "        self.confusion_mat = confusion_matrix(self.labels, self.ans_list)\n",
    "        \n",
    "        self.PrintResult()\n",
    "        \n",
    "        return self.acc, self.confusion_mat, self.ans_list\n",
    "    \n",
    "    def QueryImgs_batch(self, question, true_string=\"yes\"):\n",
    "        self.labels = []\n",
    "        self.label_3class = []\n",
    "        self.ans_list = []\n",
    "        self.question = question\n",
    "        \n",
    "        for image, label, is_uncommon in tqdm(self.dataloader):\n",
    "            \n",
    "            image = image.to(self.device)\n",
    "            \n",
    "            questions = [self.question] * image.shape[0]\n",
    "            samples = {\"image\": image, \"text_input\": questions}\n",
    "            \n",
    "            ans = self.model.predict_answers(samples=samples, inference_method=\"generate\")\n",
    "            pred_label = [0 if a == true_string else 1 for a in ans]\n",
    "            self.ans_list += pred_label\n",
    "            \n",
    "            label = [0 if l == true_string else 1 for l in label]\n",
    "            self.labels += label\n",
    "            \n",
    "            label_3class = label.copy()\n",
    "            label_3class = [2 if is_uncommon[idx] else l for idx, l in enumerate(label)]\n",
    "            \n",
    "            self.label_3class += label_3class\n",
    "        \n",
    "        self.acc = accuracy_score(self.labels, self.ans_list)\n",
    "        self.confusion_mat = confusion_matrix(self.labels, self.ans_list)\n",
    "        \n",
    "        self.PrintResult()\n",
    "        \n",
    "        self.ans_list = np.array(self.ans_list)\n",
    "        self.labels = np.array(self.labels)\n",
    "        self.label_3class = np.array(self.label_3class)\n",
    "        \n",
    "        return self.acc, self.confusion_mat, self.ans_list, self.labels, self.label_3class\n",
    "    \n",
    "    def Query(self, image, question):\n",
    "        image = self.vis_processors[\"eval\"](image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        samples = {\"image\": image, \"text_input\": question}\n",
    "        ans = self.model.predict_answers(samples=samples, inference_method=\"generate\")[0]\n",
    "        return ans\n",
    "\n",
    "    def PrintResult(self, three_class=False, acc=None, confusion_mat=None, ans_list=None, labels=None, label_3class=None):\n",
    "        \n",
    "        if acc:\n",
    "            self.acc = acc\n",
    "        if confusion_mat:\n",
    "            self.confusion_mat = confusion_mat\n",
    "        if ans_list:\n",
    "            self.ans_list = ans_list\n",
    "        if labels:\n",
    "            self.labels = labels\n",
    "        if label_3class:\n",
    "            self.label_3class = label_3class\n",
    "        \n",
    "        if three_class:\n",
    "            #assert type(self.num) == list, \"Type of num should be list.\"\n",
    "            \n",
    "            print(f'Question: {self.question}\\n')\n",
    "            \n",
    "            print(f'=== Overall ===')\n",
    "            print(f'Acc: {self.acc*100:.2f}%')\n",
    "            self.PrintConfusion(self.confusion_mat)\n",
    "            print('\\n')\n",
    "            \n",
    "            real_ans_list = self.ans_list[self.label_3class==0]\n",
    "            real_label = [0] * len(real_ans_list)\n",
    "            self.real_acc = accuracy_score(real_label, real_ans_list)\n",
    "            self.real_confusion_mat = confusion_matrix(real_label, real_ans_list, labels=[0,1])\n",
    "            print(f'=== Real images ===')\n",
    "            print(f'Acc: {self.real_acc*100:.2f}%')\n",
    "            self.PrintConfusion(self.real_confusion_mat)\n",
    "            print('\\n')\n",
    "            \n",
    "            com_ans_list = self.ans_list[self.label_3class==1]\n",
    "            com_label = [1] * len(com_ans_list)\n",
    "            self.com_acc = accuracy_score(com_label, com_ans_list)\n",
    "            self.com_confusion_mat = confusion_matrix(com_label, com_ans_list, labels=[0,1])\n",
    "            print(f'=== Common fake images ===')\n",
    "            print(f'Acc: {self.com_acc*100:.2f}%')\n",
    "            self.PrintConfusion(self.com_confusion_mat)\n",
    "            print('\\n')\n",
    "            \n",
    "            uncom_ans_list = self.ans_list[self.label_3class==2]\n",
    "            uncom_label = [1] * len(uncom_ans_list)\n",
    "            self.uncom_acc = accuracy_score(uncom_label, uncom_ans_list)\n",
    "            self.uncom_confusion_mat = confusion_matrix(uncom_label, uncom_ans_list, labels=[0,1])\n",
    "            print(f'=== Uncommon fake images ===')\n",
    "            print(f'Acc: {self.uncom_acc*100:.2f}%')\n",
    "            self.PrintConfusion(self.uncom_confusion_mat)\n",
    "        else:\n",
    "            print(f'Question: {self.question}\\n')\n",
    "            print(f'Acc: {self.acc*100:.2f}%')\n",
    "            self.PrintConfusion(self.confusion_mat)\n",
    "    \n",
    "    def PrintConfusion(self, mat):\n",
    "        padding = ' '\n",
    "        print(f'         | Pred true | Pred false |')\n",
    "        print(f'GT true  | {mat[0, 0]:{padding}<{10}}| {mat[0, 1]:{padding}<{11}}|')\n",
    "        print(f'GT false | {mat[1, 0]:{padding}<{10}}| {mat[1, 1]:{padding}<{11}}|')\n",
    "        \n",
    "    def MultipleAns(self, ans1, ans2):\n",
    "    \n",
    "        # Q1: Is this photo common in real world?\n",
    "        # Q2: Is this photo generated by a model?\n",
    "        \n",
    "        final_ans = []\n",
    "        for ans in zip(ans1, ans2):\n",
    "            if ans[0] == 0 and ans[1] == 0:\n",
    "                final_ans.append(0)\n",
    "            else:\n",
    "                final_ans.append(1)\n",
    "        \n",
    "        acc = accuracy_score(self.labels, final_ans)\n",
    "        confusion_mat = confusion_matrix(self.labels, final_ans)\n",
    "        print(f'Accuracy: {acc*100:.2f}%')\n",
    "        self.PrintConfusion(confusion_mat)\n",
    "        \n",
    "        self.ans_list = final_ans\n",
    "        self.acc = acc\n",
    "        self.confusion_mat = confusion_mat\n",
    "        \n",
    "        return acc, confusion_mat, final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer OK!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>device = torch.device(<span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch.cuda.is_available() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"cpu\"</span>)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 #device = \"cpu\"</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 model, vis_processors, txt_processors = load_model_and_preprocess(name=<span style=\"color: #808000; text-decoration-color: #808000\">\"blip2_vicuna_ins</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 #model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instru</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 #instruct = InstructBLIP(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=Tr</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">206</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_model_and_preprocess</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model_cls = registry.get_model_class(name)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">204 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">205 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># load model</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>206 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model = model_cls.from_pretrained(model_type=model_type)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">207 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_eval:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model.eval()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 67 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">- model (nn.Module): pretrained or finetuned model, depending on the configu</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 68 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model_cfg = OmegaConf.load(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.default_config_path(model_type)).model              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.from_config(model_cfg)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/blip2_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">blip2_vicuna_instruct_textinv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">853</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_config</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">850 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">851 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>load_finetuned = cfg.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"load_finetuned\"</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">852 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>853 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">854 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>vit_model=vit_model,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">855 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>img_size=img_size,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">856 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>drop_path_rate=drop_path_rate,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/blip2_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">blip2_vicuna_instruct_textinv.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">72</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#------ Visual encoder ------#</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 72 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.visual_encoder, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.ln_vision = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.init_vision_encoder(                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>vit_model, img_size, drop_path_rate, use_grad_checkpoint, vit_precision        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/blip2_models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">blip2.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">72</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">init_vision_encoder</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"clip_L\"</span>,                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>], <span style=\"color: #808000; text-decoration-color: #808000\">\"vit model must be eva_clip_g, eva2_clip_L or clip_L\"</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> model_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"eva_clip_g\"</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 72 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>visual_encoder = create_eva_vit_g(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>img_size, drop_path_rate, use_grad_checkpoint, precision                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 #         elif model_name == \"eva2_clip_L\":</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eva_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">429</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">create_eva_vit_g</span>                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">426 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">427 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">create_eva_vit_g</span>(img_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">224</span>,drop_path_rate=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.4</span>,use_checkpoint=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,precision=<span style=\"color: #808000; text-decoration-color: #808000\">\"fp1</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>429 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model = VisionTransformer(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">430 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>img_size=img_size,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">431 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>patch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span>,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">432 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>use_mean_pooling=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eva_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">278</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">275 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>dpr = [x.item() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> torch.linspace(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, drop_path_rate, depth)]  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># stochastic</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_rel_pos_bias = use_rel_pos_bias                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>278 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.blocks = nn.ModuleList([                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>Block(                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">280 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bi   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=n   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eva_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">279</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>dpr = [x.item() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> torch.linspace(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>, drop_path_rate, depth)]  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># stochastic</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">277 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_rel_pos_bias = use_rel_pos_bias                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.blocks = nn.ModuleList([                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>279 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>Block(                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">280 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bi   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=n   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>init_values=init_values, window_size=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.patch_embed.patch_shape <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> use   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eva_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.drop_path = DropPath(drop_path) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> drop_path &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> nn.Identity()          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.norm2 = norm_layer(dim)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>mlp_hidden_dim = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>(dim * mlp_ratio)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_la   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> init_values <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> init_values &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.gamma_1 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">Tr</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/LAVIS/lavis/models/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">eva_vit.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">51</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 48 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_features = hidden_features <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> in_features                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 49 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fc1 = nn.Linear(in_features, hidden_features)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.act = act_layer()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 51 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fc2 = nn.Linear(hidden_features, out_features)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 52 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.drop = nn.Dropout(drop)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">101</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 98 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias = Parameter(torch.empty(out_features, **factory_kwargs))             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 99 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">100 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.register_parameter(<span style=\"color: #808000; text-decoration-color: #808000\">'bias'</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>101 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reset_parameters()                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reset_parameters</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Setting a=sqrt(5) in kaiming_uniform is the same as initializing with</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">linear.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">107</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reset_parameters</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">104 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Setting a=sqrt(5) in kaiming_uniform is the same as initializing with</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># https://github.com/pytorch/pytorch/issues/57109</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>107 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>init.kaiming_uniform_(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, a=math.sqrt(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>))                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">108 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>fan_in, _ = init._calculate_fan_in_and_fan_out(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>bound = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> / math.sqrt(fan_in) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> fan_in &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">init.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">412</span> in          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">kaiming_uniform_</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">409 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>std = gain / math.sqrt(fan)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">410 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>bound = math.sqrt(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3.0</span>) * std  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calculate uniform bounds from standard deviation</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">411 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>412 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tensor.uniform_(-bound, bound)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">413 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">414 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">415 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">kaiming_normal_</span>(                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mdevice = torch.device(\u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m \u001b[94mif\u001b[0m torch.cuda.is_available() \u001b[94melse\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mcpu\u001b[0m\u001b[33m\"\u001b[0m)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m#device = \"cpu\"\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 model, vis_processors, txt_processors = load_model_and_preprocess(name=\u001b[33m\"\u001b[0m\u001b[33mblip2_vicuna_ins\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[2m#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instru\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m#instruct = InstructBLIP(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=Tr\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m206\u001b[0m in \u001b[92mload_model_and_preprocess\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   \u001b[0mmodel_cls = registry.get_model_class(name)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m205 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# load model\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m206 \u001b[2m│   \u001b[0mmodel = model_cls.from_pretrained(model_type=model_type)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m207 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m208 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m is_eval:                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   │   \u001b[0mmodel.eval()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33mbase_model.py\u001b[0m:\u001b[94m70\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 67 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33m- model (nn.Module): pretrained or finetuned model, depending on the configu\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 68 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_cfg = OmegaConf.load(\u001b[96mcls\u001b[0m.default_config_path(model_type)).model              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 70 \u001b[2m│   │   \u001b[0mmodel = \u001b[96mcls\u001b[0m.from_config(model_cfg)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m model                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/blip2_models/\u001b[0m\u001b[1;33mblip2_vicuna_instruct_textinv.py\u001b[0m:\u001b[94m853\u001b[0m in \u001b[92mfrom_config\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m850 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m851 \u001b[0m\u001b[2m│   │   \u001b[0mload_finetuned = cfg.get(\u001b[33m\"\u001b[0m\u001b[33mload_finetuned\u001b[0m\u001b[33m\"\u001b[0m, \u001b[94mTrue\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m852 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m853 \u001b[2m│   │   \u001b[0mmodel = \u001b[96mcls\u001b[0m(                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m854 \u001b[0m\u001b[2m│   │   │   \u001b[0mvit_model=vit_model,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m855 \u001b[0m\u001b[2m│   │   │   \u001b[0mimg_size=img_size,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m856 \u001b[0m\u001b[2m│   │   │   \u001b[0mdrop_path_rate=drop_path_rate,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/blip2_models/\u001b[0m\u001b[1;33mblip2_vicuna_instruct_textinv.py\u001b[0m:\u001b[94m72\u001b[0m in \u001b[92m__init__\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#------ Visual encoder ------#\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 72 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.visual_encoder, \u001b[96mself\u001b[0m.ln_vision = \u001b[96mself\u001b[0m.init_vision_encoder(                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   │   \u001b[0mvit_model, img_size, drop_path_rate, use_grad_checkpoint, vit_precision        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/blip2_models/\u001b[0m\u001b[1;33mblip2.py\u001b[0m:\u001b[94m72\u001b[0m in \u001b[92minit_vision_encoder\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mclip_L\u001b[0m\u001b[33m\"\u001b[0m,                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   \u001b[0m], \u001b[33m\"\u001b[0m\u001b[33mvit model must be eva_clip_g, eva2_clip_L or clip_L\u001b[0m\u001b[33m\"\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m model_name == \u001b[33m\"\u001b[0m\u001b[33meva_clip_g\u001b[0m\u001b[33m\"\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 72 \u001b[2m│   │   │   \u001b[0mvisual_encoder = create_eva_vit_g(                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mimg_size, drop_path_rate, use_grad_checkpoint, precision                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m#         elif model_name == \"eva2_clip_L\":\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33meva_vit.py\u001b[0m:\u001b[94m429\u001b[0m in \u001b[92mcreate_eva_vit_g\u001b[0m                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m426 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m427 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m428 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcreate_eva_vit_g\u001b[0m(img_size=\u001b[94m224\u001b[0m,drop_path_rate=\u001b[94m0.4\u001b[0m,use_checkpoint=\u001b[94mFalse\u001b[0m,precision=\u001b[33m\"\u001b[0m\u001b[33mfp1\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m429 \u001b[2m│   \u001b[0mmodel = VisionTransformer(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m430 \u001b[0m\u001b[2m│   │   \u001b[0mimg_size=img_size,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m431 \u001b[0m\u001b[2m│   │   \u001b[0mpatch_size=\u001b[94m14\u001b[0m,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m432 \u001b[0m\u001b[2m│   │   \u001b[0muse_mean_pooling=\u001b[94mFalse\u001b[0m,                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33meva_vit.py\u001b[0m:\u001b[94m278\u001b[0m in \u001b[92m__init__\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m275 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   \u001b[0mdpr = [x.item() \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m torch.linspace(\u001b[94m0\u001b[0m, drop_path_rate, depth)]  \u001b[2m# stochastic\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.use_rel_pos_bias = use_rel_pos_bias                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m278 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.blocks = nn.ModuleList([                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   │   │   \u001b[0mBlock(                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bi   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdrop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=n   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33meva_vit.py\u001b[0m:\u001b[94m279\u001b[0m in \u001b[92m<listcomp>\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   \u001b[0mdpr = [x.item() \u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m torch.linspace(\u001b[94m0\u001b[0m, drop_path_rate, depth)]  \u001b[2m# stochastic\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m277 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.use_rel_pos_bias = use_rel_pos_bias                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.blocks = nn.ModuleList([                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m279 \u001b[2m│   │   │   \u001b[0mBlock(                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bi   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdrop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=n   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minit_values=init_values, window_size=\u001b[96mself\u001b[0m.patch_embed.patch_shape \u001b[94mif\u001b[0m use   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33meva_vit.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92m__init__\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.drop_path = DropPath(drop_path) \u001b[94mif\u001b[0m drop_path > \u001b[94m0.\u001b[0m \u001b[94melse\u001b[0m nn.Identity()          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.norm2 = norm_layer(dim)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0mmlp_hidden_dim = \u001b[96mint\u001b[0m(dim * mlp_ratio)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_la   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m init_values \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m init_values > \u001b[94m0\u001b[0m:                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.gamma_1 = nn.Parameter(init_values * torch.ones((dim)),requires_grad=\u001b[94mTr\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/LAVIS/lavis/models/\u001b[0m\u001b[1;33meva_vit.py\u001b[0m:\u001b[94m51\u001b[0m in \u001b[92m__init__\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 48 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_features = hidden_features \u001b[95mor\u001b[0m in_features                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.fc1 = nn.Linear(in_features, hidden_features)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.act = act_layer()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 51 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.fc2 = nn.Linear(hidden_features, out_features)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.drop = nn.Dropout(drop)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 54 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x):                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m101\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.bias = Parameter(torch.empty(out_features, **factory_kwargs))             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.register_parameter(\u001b[33m'\u001b[0m\u001b[33mbias\u001b[0m\u001b[33m'\u001b[0m, \u001b[94mNone\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m101 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.reset_parameters()                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mreset_parameters\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mlinear.py\u001b[0m:\u001b[94m107\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mreset_parameters\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m104 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[0m            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m107 \u001b[2m│   │   \u001b[0minit.kaiming_uniform_(\u001b[96mself\u001b[0m.weight, a=math.sqrt(\u001b[94m5\u001b[0m))                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m108 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.bias \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0mfan_in, _ = init._calculate_fan_in_and_fan_out(\u001b[96mself\u001b[0m.weight)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0mbound = \u001b[94m1\u001b[0m / math.sqrt(fan_in) \u001b[94mif\u001b[0m fan_in > \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m \u001b[94m0\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/denny/anaconda3/envs/instblip/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33minit.py\u001b[0m:\u001b[94m412\u001b[0m in          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mkaiming_uniform_\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m409 \u001b[0m\u001b[2m│   \u001b[0mstd = gain / math.sqrt(fan)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m410 \u001b[0m\u001b[2m│   \u001b[0mbound = math.sqrt(\u001b[94m3.0\u001b[0m) * std  \u001b[2m# Calculate uniform bounds from standard deviation\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m411 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m412 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m tensor.uniform_(-bound, bound)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m413 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m414 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m415 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mkaiming_normal_\u001b[0m(                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_vicuna_instruct_textinv\", model_type=\"vicuna7b\", is_eval=True, device=device)\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instruct\", model_type=\"flant5xl\", is_eval=True, device=device)\n",
    "#instruct = InstructBLIP(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "instruct = InstructBLIP()\n",
    "instruct.LoadModels(model, vis_processors, txt_processors, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "#image = Image.open(\"/eva_data0/denny/coco2014/val2014/COCO_val2014_000000000042.jpg\")\n",
    "image = Image.open(\"/eva_data0/denny/sd2/coco2014_train/samples/00000.png\")\n",
    "questions = [\"Is this photo [*]?\"]\n",
    "ans = instruct.Query(image, questions)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/777 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 777/777 [09:49<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo [*]?\n",
      "\n",
      "Acc: 92.28%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 2805      | 287        |\n",
      "GT false | 193       | 2930       |\n",
      "Acc: 92.28%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 2805      | 287        |\n",
      "GT false | 193       | 2930       |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/eva_data0/denny/textual_inversion/total_60k/60k_test_label.csv\"\n",
    "#csv_path = \"/eva_data0/denny/debug_label.csv\"\n",
    "instruct.LoadData_batch(csv_path=csv_path)\n",
    "\n",
    "question = \"Is this photo [*]?\"\n",
    "acc, confusion_mat, ans_list, labels, label_3class = instruct.QueryImgs_batch(question=question, true_string=\"yes\")\n",
    "print(f'Acc: {acc*100:.2f}%')\n",
    "instruct.PrintConfusion(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo [*]?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 92.28%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 2805      | 287        |\n",
      "GT false | 193       | 2930       |\n",
      "\n",
      "\n",
      "=== Real images ===\n",
      "Acc: 90.72%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 2805      | 287        |\n",
      "GT false | 0         | 0          |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 89.19%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 167       | 1378       |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 98.35%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 26        | 1552       |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading imgs from /eva_data0/denny/coco2014/train2014: 100%|██████████| 200/200 [00:03<00:00, 51.07it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/SD2/0_real/: 100%|██████████| 100/100 [00:02<00:00, 33.49it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/SD2/1_fake/: 100%|██████████| 100/100 [00:03<00:00, 32.72it/s]\n"
     ]
    }
   ],
   "source": [
    "real_dir = \"/eva_data0/denny/coco2014/train2014\"\n",
    "fake_common_dir = \"/eva_data0/denny/SemanticError/SD2/0_real/\"\n",
    "fake_uncommon_dir = \"/eva_data0/denny/SemanticError/SD2/1_fake/\"\n",
    "real_num = 200\n",
    "num = [real_num, real_num//2, real_num//2]\n",
    "#num = [50, 25, 25]\n",
    "instruct.LoadData3Class(real_dir, fake_common_dir, fake_uncommon_dir, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 400/400 [02:17<00:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo [*]?\n",
      "\n",
      "Acc: 96.25%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 186       | 14         |\n",
      "GT false | 1         | 199        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc1, mat1, ans1 = instruct.QueryImgs(\"Is this photo [*]?\", true_string=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo [*]?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 96.25%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 186       | 14         |\n",
      "GT false | 1         | 199        |\n",
      "\n",
      "\n",
      "=== Real images ===\n",
      "Acc: 93.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 186       | 14         |\n",
      "GT false | 0         | 0          |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 99.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 1         | 99         |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 100.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 0         | 100        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [09:48<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "\n",
      "Acc: 79.40%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 819       | 181        |\n",
      "GT false | 231       | 769        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc1, mat1, ans1 = instruct.QueryImgs(\"Is this photo common in real world?\", true_string=\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 79.40%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 819       | 181        |\n",
      "GT false | 231       | 769        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 64.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 180       | 320        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 89.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 51        | 449        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Real images ===\n",
      "Acc: 81.90%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 819       | 181        |\n",
      "GT false | 231       | 769        |\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mat = np.array([[819,181],[231,769]])\n",
    "print(f'=== Real images ===')\n",
    "print(f'Acc: {(mat[0,0]/1000)*100:.2f}%')\n",
    "instruct.PrintConfusion(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [15:43<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by a model?\n",
      "\n",
      "Acc: 66.10%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 658       | 342        |\n",
      "GT false | 336       | 664        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo generated by a model?\"\n",
    "acc2, mat2, ans2 = instruct.QueryImgs(question, true_string=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by a model?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 66.10%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 658       | 342        |\n",
      "GT false | 336       | 664        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 71.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 141       | 359        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 61.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 195       | 305        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.85%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 560       | 440        |\n",
      "GT false | 103       | 897        |\n"
     ]
    }
   ],
   "source": [
    "acc, confusion_mat, ans = instruct.MultipleAns(ans1, ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by a model?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 72.85%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 560       | 440        |\n",
      "GT false | 103       | 897        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 85.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 71        | 429        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 93.60%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 32        | 468        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [10:16<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by AI?\n",
      "\n",
      "Acc: 50.75%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 998       | 2          |\n",
      "GT false | 983       | 17         |\n",
      "Question: Is this photo generated by AI?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 50.75%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 998       | 2          |\n",
      "GT false | 983       | 17         |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 2.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 486       | 14         |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 0.60%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 497       | 3          |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo generated by AI?\"\n",
    "instruct.QueryImgs(question, true_string=\"no\")\n",
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by AI?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 50.75%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 998       | 2          |\n",
      "GT false | 983       | 17         |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 2.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 486       | 14         |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 0.60%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 497       | 3          |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 200/200 [01:25<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "\n",
      "Acc: 81.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 82        | 18         |\n",
      "GT false | 20        | 80         |\n",
      "Question: Is this photo common in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 81.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 82        | 18         |\n",
      "GT false | 20        | 80         |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 74.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 13        | 37         |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 86.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 7         | 43         |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo common in real world?\"\n",
    "acc1, mat1, ans1 = instruct.QueryImgs(question, true_string=\"yes\")\n",
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 80.25%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 836       | 164        |\n",
      "GT false | 231       | 769        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 64.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 180       | 320        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 89.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 51        | 449        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [16:25<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo possible in real world?\n",
      "\n",
      "Acc: 57.45%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 740       | 260        |\n",
      "GT false | 591       | 409        |\n",
      "Question: Is this photo possible in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 57.45%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 740       | 260        |\n",
      "GT false | 591       | 409        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 39.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 301       | 199        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 42.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 290       | 210        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo possible in real world?\"\n",
    "instruct.QueryImgs(question, true_string=\"yes\")\n",
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo possible in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 57.45%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 740       | 260        |\n",
      "GT false | 591       | 409        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 39.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 301       | 199        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 42.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 290       | 210        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading imgs from /eva_data0/denny/coco2014/train2014: 100%|██████████| 1000/1000 [00:03<00:00, 252.17it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/IF/0_real/: 100%|██████████| 500/500 [00:13<00:00, 35.73it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/IF/1_fake/: 100%|██████████| 500/500 [00:14<00:00, 33.47it/s]\n"
     ]
    }
   ],
   "source": [
    "real_dir = \"/eva_data0/denny/coco2014/train2014\"\n",
    "fake_common_dir = \"/eva_data0/denny/SemanticError/IF/0_real/\"\n",
    "fake_uncommon_dir = \"/eva_data0/denny/SemanticError/IF/1_fake/\"\n",
    "real_num = 1000\n",
    "num = [real_num, real_num//2, real_num//2]\n",
    "#num = [50, 25, 25]\n",
    "instruct.LoadData3Class(real_dir, fake_common_dir, fake_uncommon_dir, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [09:40<00:00,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "\n",
      "Acc: 74.95%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 836       | 164        |\n",
      "GT false | 337       | 663        |\n",
      "Question: Is this photo common in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 74.95%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 836       | 164        |\n",
      "GT false | 337       | 663        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 39.60%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 302       | 198        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 93.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 35        | 465        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo common in real world?\"\n",
    "acc1, mat1, ans1 = instruct.QueryImgs(question, true_string=\"yes\")\n",
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 74.95%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 836       | 164        |\n",
      "GT false | 337       | 663        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 39.60%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 302       | 198        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 93.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 35        | 465        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [17:05<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by a model?\n",
      "\n",
      "Acc: 63.95%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 645       | 355        |\n",
      "GT false | 366       | 634        |\n",
      "Question: Is this photo generated by a model?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 63.95%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 645       | 355        |\n",
      "GT false | 366       | 634        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 63.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 185       | 315        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 63.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 181       | 319        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo generated by a model?\"\n",
    "acc2, mat2, ans2 = instruct.QueryImgs(question, true_string=\"no\")\n",
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by a model?\n",
      "\n",
      "=== Overall ===\n",
      "Acc: 63.95%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 645       | 355        |\n",
      "GT false | 366       | 634        |\n",
      "\n",
      "\n",
      "=== Common fake images ===\n",
      "Acc: 63.00%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 185       | 315        |\n",
      "\n",
      "\n",
      "=== Uncommon fake images ===\n",
      "Acc: 63.80%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 181       | 319        |\n"
     ]
    }
   ],
   "source": [
    "instruct.PrintResult(three_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.60%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 554       | 446        |\n",
      "GT false | 162       | 838        |\n"
     ]
    }
   ],
   "source": [
    "acc, confusion_mat, ans = instruct.MultipleAns(ans1, ans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instruct\", model_type=\"flant5xl\", is_eval=True, device=device)\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instruct\", model_type=\"flant5xxl\", is_eval=True, device=device)\n",
    "model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=True, device=device)\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_vicuna_instruct\", model_type=\"vicuna13b\", is_eval=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading imgs from /eva_data0/denny/coco2014/train2014: 100%|██████████| 1000/1000 [00:03<00:00, 257.93it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/SD2/0_real/: 100%|██████████| 1000/1000 [00:22<00:00, 45.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# For query lots of images\n",
    "real_dir = \"/eva_data0/denny/coco2014/train2014\"\n",
    "fake_dir = \"/eva_data0/denny/SemanticError/SD2/0_real/\"\n",
    "#imgs, labels = PrepareData(\"/eva_data0/denny/SemanticError/SD2/test/\")\n",
    "imgs, labels = PrepareData(real_dir, fake_dir, num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [17:37<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo possible in real world?\n",
      "Acc: 56.85%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 716       | 284        |\n",
      "GT false | 579       | 421        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For query lots of images\n",
    "question = \"Is this photo possible in real world?\"\n",
    "acc, confusion_mat, com_acc, com_conf_mat, uncom_acc, uncom_conf_mat = QueryImgs(imgs, labels, question, model, vis_processors, txt_processors, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "PrintConfusion(confusion_mat)\n",
    "\n",
    "print(com_acc)\n",
    "PrintConfusion(com_conf_mat)\n",
    "print(uncom_acc)\n",
    "PrintConfusion(uncom_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading imgs from /eva_data0/denny/coco2014/train2014: 100%|██████████| 200/200 [00:01<00:00, 199.41it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/SD2/1_fake/: 100%|██████████| 200/200 [00:03<00:00, 56.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# For query lots of images\n",
    "real_dir = \"/eva_data0/denny/coco2014/train2014\"\n",
    "fake_dir = \"/eva_data0/denny/SemanticError/SD2/1_fake/\"\n",
    "#imgs, labels = PrepareData(\"/eva_data0/denny/SemanticError/SD2/test/\")\n",
    "imgs, labels = PrepareData(real_dir, fake_dir, num=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 200/200 [01:31<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo possible in real world?\n",
      "Acc: 60.50%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 74        | 26         |\n",
      "GT false | 53        | 47         |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For query lots of images\n",
    "question = \"Is this photo possible in real world?\"\n",
    "acc, confusion_mat, com_acc, com_conf_mat, uncom_acc, uncom_conf_mat = QueryImgs(imgs, labels, question, model, vis_processors, txt_processors, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.605\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 74        | 26         |\n",
      "GT false | 53        | 47         |\n",
      "0.46\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 27        | 23         |\n",
      "0.46\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 27        | 23         |\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "PrintConfusion(confusion_mat)\n",
    "\n",
    "print(com_acc)\n",
    "PrintConfusion(com_conf_mat)\n",
    "print(uncom_acc)\n",
    "PrintConfusion(uncom_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [10:51<00:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo common in real world?\n",
      "Acc: 83.70%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 812       | 188        |\n",
      "GT false | 138       | 862        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For query lots of images\n",
    "question = \"Is this photo common in real world?\"\n",
    "acc, confusion_mat = QueryImgs(imgs, labels, question, model, vis_processors, txt_processors, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering: 100%|██████████| 2000/2000 [15:58<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is this photo generated by a model?\n",
      "Acc: 62.55%\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 630       | 370        |\n",
      "GT false | 379       | 621        |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo generated by a model?\"\n",
    "acc, confusion_mat = QueryImgs(imgs, labels, question, model, vis_processors, txt_processors, device, true_string=\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading imgs from /eva_data0/denny/coco2014/train2014: 100%|██████████| 1000/1000 [00:04<00:00, 244.46it/s]\n",
      "Loading imgs from /eva_data0/denny/SemanticError/SD2/real_and_fake/: 100%|██████████| 1000/1000 [00:10<00:00, 91.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# For query lots of images\n",
    "real_dir = \"/eva_data0/denny/coco2014/train2014\"\n",
    "fake_dir = \"/eva_data0/denny/SemanticError/SD2/real_and_fake/\"\n",
    "#imgs, labels = PrepareData(\"/eva_data0/denny/SemanticError/SD2/test/\")\n",
    "imgs, labels = PrepareData(real_dir, fake_dir, num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering:  84%|████████▎ | 1671/2000 [13:03<02:13,  2.46it/s]"
     ]
    }
   ],
   "source": [
    "question = \"Is this photo generated by a model?\"\n",
    "acc, confusion_mat, com_acc, com_conf_mat, uncom_acc, uncom_conf_mat = QueryImgs(imgs, labels, question, model, vis_processors, txt_processors, device, true_string=\"no\")\n",
    "print(acc)\n",
    "PrintConfusion(confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 64        | 36         |\n",
      "GT false | 21        | 79         |\n",
      "0.78\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 11        | 39         |\n",
      "0.78\n",
      "         | Pred true | Pred false |\n",
      "GT true  | 0         | 0          |\n",
      "GT false | 11        | 39         |\n"
     ]
    }
   ],
   "source": [
    "print(acc)\n",
    "PrintConfusion(confusion_mat)\n",
    "\n",
    "print(com_acc)\n",
    "PrintConfusion(com_conf_mat)\n",
    "print(uncom_acc)\n",
    "PrintConfusion(uncom_conf_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load an example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_image = Image.open(\"../docs/_static/merlion.png\").convert(\"RGB\")\n",
    "raw_image = Image.open(\"/eva_data/denny/SemanticError/SD2/1_fake/00000.png\").convert(\"RGB\")\n",
    "#display(raw_image.resize((596, 437)))\n",
    "display(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device to use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load instructBLIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instruct\", model_type=\"flant5xl\", is_eval=True, device=device)\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_t5_instruct\", model_type=\"flant5xxl\", is_eval=True, device=device)\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_vicuna_instruct\", model_type=\"vicuna7b\", is_eval=True, device=device)\n",
    "#model, vis_processors, txt_processors = load_model_and_preprocess(name=\"blip2_vicuna_instruct\", model_type=\"vicuna13b\", is_eval=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_processors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_processors.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"Which city is this photo taken?\"\n",
    "#question = \"What is the animal in the photo?\"\n",
    "question = \"Is this photo possible in real world?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use \"eval\" processors for inference\n",
    "image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n",
    "question = txt_processors[\"eval\"](question)\n",
    "\n",
    "samples = {\"image\": image, \"text_input\": question}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generative question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_answers(samples=samples, inference_method=\"generate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ranking-based question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank answer candidates by their likelihood and return the best answer\n",
    "answer_candidates = [\"Singapore\", \"London\", \"Palo Alto\", \"Tokyo\"]\n",
    "\n",
    "model.predict_answers(samples, answer_list=answer_candidates, inference_method=\"rank\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ask questions in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "# create a batch of samples, could be multiple images or copies of the same image\n",
    "image_batch = image.repeat(batch_size, 1, 1, 1)\n",
    "\n",
    "# create a batch of questions, make sure the number of questions matches the number of images\n",
    "question_1 = txt_processors[\"eval\"](\"Which city is this photo taken?\")\n",
    "question_2 = txt_processors[\"eval\"](\"What time is this during the day?\")\n",
    "question_3 = txt_processors[\"eval\"](\"Is it Singapore or London?\")\n",
    "\n",
    "question_batch = [question_1, question_2, question_3]\n",
    "\n",
    "model.predict_answers(samples={\"image\": image_batch, \"text_input\": question_batch}, inference_method=\"generate\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instblip",
   "language": "python",
   "name": "instblip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
